# Proyecto_ETL

# Proyecto ETL: An√°lisis de Reservas Hoteleras en Madrid

## Descripci√≥n del Proyecto
Nuestra empresa, dedicada al sector hotelero en Madrid, ha recibido un archivo en formato Parquet con informaci√≥n sobre reservas de hoteles propios y de la competencia. El objetivo de este proyecto es extraer, transformar y cargar (ETL) estos datos para generar insights relevantes.

## Requisitos del Proyecto

### 1. Extracci√≥n de Datos
- Leer el archivo `reservas_hoteles.parquet` para obtener informaci√≥n sobre hoteles de la competencia.
- Realizar web scraping de una p√°gina de hoteles dada.

### 2. Obtenci√≥n de Datos de Eventos
- Consultar la API del Ayuntamiento de Madrid para obtener eventos en la ciudad durante las fechas de las reservas.

### 3. Transformaci√≥n de Datos
- Limpiar y estructurar los datos extra√≠dos de la web para que sean comparables con los datos del archivo original.
- Enriquecer los datos de reservas con informaci√≥n de eventos en Madrid en las mismas fechas.

### 4. Carga de Datos
- Almacenar los datos transformados en una base de datos SQL.

## Estructura de la Base de Datos
Se ha utilizado PostgreSQL para almacenar los datos en las siguientes tablas:
```sql
CREATE TABLE ciudad (
    id_ciudad SERIAL PRIMARY KEY,
    nombre_ciudad TEXT
);

CREATE TABLE eventos (
    id_evento SERIAL PRIMARY KEY,
    nombre_evento TEXT,
    url_evento TEXT,
    codigo_postal TEXT,
    direccion TEXT,
    horario TEXT,
    fecha_inicio DATE,
    fecha_fin DATE,
    organizacion TEXT,
    id_ciudad INT REFERENCES ciudad(id_ciudad) ON DELETE CASCADE
);

CREATE TABLE hoteles (
    id_hotel SERIAL PRIMARY KEY,
    nombre_hotel TEXT,
    competencia BOOL,
    valoracion FLOAT CHECK (valoracion BETWEEN 1 AND 5),
    id_ciudad INT REFERENCES ciudad(id_ciudad) ON DELETE CASCADE
);

CREATE TABLE clientes (
    id_cliente VARCHAR(50) PRIMARY KEY,
    nombre TEXT,
    apellido TEXT,
    mail TEXT UNIQUE CHECK (mail LIKE '%@%')
);

CREATE TABLE reservas (
    id_reserva VARCHAR(50) PRIMARY KEY,
    fecha_reserva DATE,
    inicio_estancia DATE,
    final_estancia DATE,
    precio_noche FLOAT CHECK (precio_noche >= 0),
    id_cliente VARCHAR(50) REFERENCES clientes(id_cliente) ON DELETE CASCADE,
    id_hotel INT REFERENCES hoteles(id_hotel) ON DELETE CASCADE
);
```

## Proceso ETL

### 1. Extracci√≥n y transformaci√≥n
#### Archivo Parquet
- Se limpiaron los datos eliminando duplicados y asegurando la integridad de las columnas.
- Se transformaron las fechas al formato correcto.
- Se generaron IDs √∫nicos para los clientes, corrigiendo inconsistencias en IDs y correos.
- Se corrigieron IDs de hoteles y nombres, asegurando una relaci√≥n uno a uno.
- Se calcul√≥ la valoraci√≥n media de cada hotel y se hizo un estudio de si exist√≠an valores outliers.
- Se imputaron a los valores nulos en los precios de las reservas el el promedio del precio por hotel y d√≠a.
- Se calcul√≥ la valoraci√≥n de cada hotel propio en funci√≥n al promedio de estrellas que ten√≠a cada uno

#### Web Scraping
- Se intent√≥ extraer informaci√≥n con BeautifulSoup, pero debido a la carga din√°mica de precios, se utiliz√≥ Selenium.
- Se extrajo nombre del hotel, valoraci√≥n, precio por noche.
- Se la asign√≥ a la fecha de reserva la fecha en la que se realiz√≥ el escrapeo.
- Se le asign√≥ a la ciudad el valor de Madrid.
- Los datos extra√≠dos se guardaron en un archivo pickle.

### Continuaci√≥n transformaci√≥n en Archivo Parquet
- Se asignaron IDs de hotel aleatoriamente a los datos del scraping para unirlos con el dataset original.
- Se incorpor√≥ esta informaci√≥n al archivo original para tener toda la informaci√≥n en un mismo fichero.
- Se elimin√≥ las columnas que no eran necesarias.
- Los datos transformados se guardadron en un archivo pickle para usarlos posteriormente en la carga a la BBDD.

#### API de Eventos de Madrid
- La informaci√≥n de los eventos fue extra√≠da de la **API de eventos de Madrid**, aplicando los siguientes filtros:
  - **Eventos que empezaran antes de la fecha fin de la estancia**, incluyendo ese d√≠a (02/03 a las 23:59:59).
  - **Eventos que finalizaran despu√©s de la fecha inicio de la estancia**, es decir, despu√©s del 01/03 a las 00:00:00.
  - Para los **eventos recurrentes**, se incluyeron solo los eventos que se repitieran en los d√≠as relevantes (01/03 y 02/03, s√°bado y domingo).
  - Si estos d√≠as coincid√≠an con los **d√≠as excluidos del evento**, no se tuvieron en cuenta.
  - Resultado: El 25/02/2025 se extrajeron **161 eventos**.

### 2. Carga en la Base de Datos

#### 1. Funciones de Soporte

Se crearon dos funciones de soporte para facilitar la carga de datos en la base de datos:

##### 1.1. **Funci√≥n de Carga de Datos**
Esta funci√≥n se encarga de:
- Crear la **conexi√≥n** y el **cursor**.
- Ejecutar la **query de inserci√≥n**.
- Recibir los siguientes par√°metros:  query de inserci√≥n y los **datos a insertar**.
- Dependiendo de si los datos a insertar son una lista o no, ejecutar una subida o varias.
- Guardar los cambios para completar la subida.
- Cerrar el **cursor** y la **conexi√≥n**.

##### 1.2. **Funci√≥n de Extracci√≥n de Datos**
Esta funci√≥n realiza lo siguiente:
- Crear la **conexi√≥n** y el **cursor**.
- Ejecutar la **query de extracci√≥n**.
- Recibir la **query de extracci√≥n** y devolver los resultados como un **diccionario**.
- Cerrar el **cursor** y la **conexi√≥n** al finalizar.

---

#### 2. Subida de Datos a la Base de Datos

Una vez creadas las funciones de soporte, proced√≠ a cargar los datos en cada una de las tablas de la base de datos en el siguiente orden:

##### 2.1. **Importaci√≥n del DataFrame Limpio**
Primero, se import√≥ el **DataFrame limpio**, que fue la base para obtener los datos correctos para la mayor√≠a de las tablas.

##### 2.2. **Subida de Datos a las tablas**

###### 2.2.1. **Tabla Ciudad - Sin clave for√°nea**
- Se extrajo la informaci√≥n de la **tabla ciudad** desde el **DataFrame limpio**.
- Se construy√≥ un **data_to_insert** con un valor √∫nico, subiendo solo el campo **ciudad**.
- El **id_ciudad** es de tipo **serial** en la base de datos, por lo que no fue necesario incluirlo.

###### 2.2.2. **Tabla Eventos - Con clave for√°nea**
- Para la **tabla eventos**, era necesario obtener el **id_ciudad**, por lo que primero se extrajo de la base de datos utilizando la funci√≥n de extracci√≥n.
- La informaci√≥n de los eventos fue extra√≠da de la **API de eventos de Madrid**, seg√∫n el proceso indicado en la extracci√≥n de la API.
- Se construy√≥ el **data_to_insert** combinando la informaci√≥n de la API con el **id_ciudad** extra√≠do de la base de datos.
- Se cre√≥ la **query de inserci√≥n** y se procedi√≥ a la **subida de los datos** a la base de datos utilizando la funci√≥n de inserci√≥n.
- El **id_evento** se gener√≥ de forma **seriada** en la base de datos.

###### 2.2.3. **Tabla Hoteles - Con clave for√°nea**
- Se cre√≥ la **tabla hoteles** a partir del **DataFrame limpio**, manteniendo solo las columnas necesarias.
- Se eliminaron los **duplicados de nombre de hoteles** y se a√±adi√≥ el **id_ciudad** extra√≠do de la base de datos para asociarlo correctamente.
- Se cre√≥ el **data_to_insert** y la **query de inserci√≥n**.
- Se procedi√≥ a la **subida de los datos** utilizando la funci√≥n de inserci√≥n.
- El **id_hotel** se gener√≥ de forma **seriada** en la base de datos.

###### 2.2.4. **Tabla Clientes - Sin clave for√°nea**
- Se cre√≥ la **tabla clientes** utilizando el **DataFrame limpio**, qued√°ndose solo con las columnas necesarias.
- Se eliminaron los **duplicados de id_clientes**.
- Se cre√≥ la **query de inserci√≥n** y se procedi√≥ a la **subida de los datos**.
- En este caso, el **id_cliente** se subi√≥ ya que no era de tipo **serial** en la base de datos.

###### 2.2.5. **Tabla Reservas - Con clave for√°nea**
- Para la **tabla reservas**, se necesitaban tanto el **id_hotel** como el **id_cliente**. Por lo tanto, se extrajo primero el **id_hotel** de la base de datos.
- Se extrajo el resto de la informaci√≥n del **DataFrame limpio** y se incorporaron tanto el **id_ciudad** como el **id_hotel** extra√≠dos previamente de la base de datos.
- Se cre√≥ la **query de inserci√≥n** y se procedi√≥ a la **subida de los datos**.
- El **id_reserva** se subi√≥ ya que no era de tipo **serial** en la base de datos.


## 3. An√°lisis y Consultas
## Consultas SQL
- N√∫mero total de hoteles: `29`
- N√∫mero total de reservas: `15000`
- Top 10 clientes que m√°s gastaron:
    - Ceferino Sosa, Leandra Casta√±eda, Modesta Heras, Clarisa Coll, Abiga√≠l Ayala. Domingo Zabaleta, Leoncio Robledo, Consuela Folch, Samuel Arco, √Ångeles Nu√±ez.
- Hotel con m√°s recaudaci√≥n:
    - **Competencia**: Novotel Madrid Center
    - **Propios**: Hotel Monte Verde
- N√∫mero total de eventos: `161`
- D√≠a con m√°s reservas: `06/02/2025` con `872` reservas.

## üìä An√°lisis Exploratorio de Datos (EDA)

### üîç An√°lisis de Precios entre la Competencia y Nuestros Hoteles  
Una vez creada la base de datos, se realizaron varias consultas para construir un **DataFrame con los datos relevantes** y analizar la diferencia de precios entre **nuestros hoteles** y los **hoteles de la competencia**.  

#### üìà **Hallazgos Principales**  
- üè® **Distribuci√≥n de hoteles**:  
  - El **65,5%** de los hoteles son **propios**, mientras que el **34,5%** pertenece a la **competencia**.  
  - Esta misma proporci√≥n se mantiene en el n√∫mero de **reservas realizadas**.  

- üí∞ **Ingresos totales**:  
  - Aunque el n√∫mero de hoteles y reservas es similar, la recaudaci√≥n es **mayor en nuestros hoteles**.  
  - **Nuestros hoteles generan el 77,3% de los ingresos**, mientras que la competencia solo **22,7%**.  

- üíµ **Diferencia en precios**:  
  - El **precio promedio por reserva** en nuestros hoteles es **275‚Ç¨**, mientras que en los hoteles de la competencia es **153‚Ç¨**.  
  - Esto sugiere que **el precio por noche no afecta la cantidad de reservas**, ya que ambos grupos tienen una **media de 517 reservas por hotel**.  

- üìä **Variabilidad en precios**:  
  - En los **hoteles de la competencia**, cada hotel tiene un **precio √∫nico** de reserva.  
  - En nuestros **hoteles propios**, los precios **var√≠an entre reservas**, pero **sin valores at√≠picos**.  

---

### ‚è≥ An√°lisis Temporal de las Fechas de Reserva  

Se analizaron las fechas en las que se realizaron las reservas para identificar patrones temporales.  

#### üìÜ **Hallazgos Principales**  
- üìÖ **Todas las reservas se realizaron en febrero**.  
- üè® **Patr√≥n de reservas por tipo de hotel**:  
  - Las **reservas en nuestros hoteles** est√°n distribuidas en diferentes d√≠as.  
  - En los **hoteles de la competencia**, todas las reservas se realizaron **el d√≠a 25**.  
- üí∏ **Ingresos diarios en nuestros hoteles**:  
  - El **importe total recaudado por d√≠a** es bastante **uniforme**.  
- üí∞ **Evoluci√≥n del precio medio por noche**:  
  - En nuestros hoteles, el precio medio ronda las **270 unidades monetarias** en todos los d√≠as.  
  - En los hoteles de la competencia, el precio medio se mantiene alrededor de **150 unidades monetarias**.  

Para m√°s detalles ejecutar el fichero main_eda.py

## üóÇÔ∏è Estructura del Proyecto
‚îÇ  
‚îú‚îÄ‚îÄ üìÇ data/             *Datos crudos y procesados* 

‚îú‚îÄ‚îÄ üìÇ notebooks/           *Notebooks de Jupyter con el an√°lisis, visualizaciones y conclusiones*

‚îú‚îÄ‚îÄ üìÇ Src/                *Scripts de procesamiento y modelado*

‚îú‚îÄ‚îÄ üìÇ Venv/                 *Entorno virtual con dependencias instaladas*

‚îú‚îÄ‚îÄ üêç main.py               *Script principal para ejecutar el proceso ETL*

‚îú‚îÄ‚îÄ üêç main_eda.py           *Script para realizar el an√°lisis exploratorio de datos*

‚îú‚îÄ‚îÄ üìÑ requirements.txt      *Lista de dependencias necesarias para el proyecto*

‚îú‚îÄ‚îÄ üìÑ README.md             # Documentaci√≥n del proyecto y conclusiones  


## Requisitos de Instalaci√≥n
Ejecutar:
```sh
pip install -r requirements.txt
```

## Ejecuci√≥n del Proyecto
### Para ejecutar el proceso ETL:
```sh
python main.py
```
### Para ejecutar el proceso del An√°lisis exploratorio de los datos (EDA) posterior:
```sh
python main_eda.py
```
## üõ†Ô∏è Tecnolog√≠as Utilizadas  

Este proyecto ha sido desarrollado utilizando **Python** y las siguientes librer√≠as:  

- **`pandas`**: Manejo y an√°lisis de datos en estructuras tipo DataFrame.  
- **`numpy`**: Operaciones matem√°ticas y manejo de arrays.  
- **`requests`**: Conexi√≥n y extracci√≥n de datos desde APIs.  
- **`pyarrow`**: Soporte para formatos de datos optimizados.  
- **`psycopg2`**: Conexi√≥n y operaciones con bases de datos **PostgreSQL**.  
- **`dotenv`**: Manejo de variables de entorno.
- **`selenium`**: Automatizaci√≥n de navegaci√≥n web para Web Scraping.
-**`beautifulsoup4`**: Extracci√≥n y procesamiento de datos desde HTML y XML.
- **`matplotlib`** y **`seaborn`**: Visualizaci√≥n de datos.  

Adem√°s, se han implementado m√≥dulos propios dentro de la carpeta `src/`, incluyendo:  
- **`soporte_api`**: Funciones para la extracci√≥n de datos desde la API del Ayuntamiento de Madrid.  
- **`soporte_limpieza`**: Procesamiento y limpieza de datos.  
- **`soporte_escrapeo`**: Funciones de Web Scraping.  
- **`soporte_carga_BBDD`**: Conexi√≥n y carga de datos en la base de datos.  
- **`soporte_EDA`**: Funciones para el an√°lisis exploratorio de datos.  

## üìä Otras tecnolog√≠as utilizadas:  
- **PostgreSQL**: Base de datos relacional para almacenar los datos procesados.  
- **APIs**: Extracci√≥n de datos en tiempo real desde fuentes oficiales, como el Ayuntamiento de Madrid.  
- **Entorno Virtual**: Se ha utilizado un entorno virtual para gestionar dependencias y asegurar la compatibilidad del c√≥digo.- 

## Conclusiones
Este proyecto permiti√≥ estructurar los datos de reservas hoteleras, extrayendo datos relevantes de la competencia por Web Scraping, complementarlos con eventos de la ciudad mediante una extracci√≥n de una API y analizarlos para extraer insights valiosos sobre la relaci√≥n entre ocupaci√≥n hotelera y eventos en Madrid.

## üîÑ Pr√≥ximos Pasos

   - Revisi√≥n del control de flujos y errores de la parte de la carga a la BBDD.


## ü§ù Contribuciones

   -  Las contribuciones son bienvenidas. Si deseas mejorar el proyecto, por favor abre un pull request o una issue, env√≠a un correo a vanesafloresrivera87@gmail.com o cont√°ctame trav√©s de [linkedin](https://www.linkedin.com/in/vanesa-flores-rivera/).


## ‚úíÔ∏è Autores

   - **Vanesa Flores Rivera**: [linkedin](https://www.linkedin.com/in/vanesa-flores-rivera/), [github](https://github.com/VanesaFloresRivera)


